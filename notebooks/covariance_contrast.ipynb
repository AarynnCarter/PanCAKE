{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrates covariance matrix approach to contrast calculation with simple, single-reference subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "from pandeia_coronagraphy import scene, analysis, engine\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Reference Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the contrast from the correlation speckle, shot, and detector noise, we'll need to create multiple realizations of target and reference observations.\n",
    "\n",
    "We begin by defining simple target and reference templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The target is just a duplicate of the template\n",
    "target = engine.load_calculation( engine.get_template('nircam_coronagraphy_template.json') )\n",
    "\n",
    "# We adopt a brighter but spectrally-mismatched reference (compared to target 5.2 mag and a5v)\n",
    "reference = engine.load_calculation( engine.get_template('nircam_coronagraphy_template.json') )\n",
    "refstar = reference['scene'][0]\n",
    "refstar['spectrum']['normalization']['norm_flux'] = 4.8\n",
    "refstar['spectrum']['sed']['key'] = 'a3v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over 10 realizations of target acquisition error (both target and reference) and the predicted WFE:\n",
    "\n",
    "\n",
    "(Note that this isn't the most efficient loop one could construct.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine.options.wave_sampling = 20 \n",
    "engine.options.on_the_fly_PSFs = True\n",
    "\n",
    "n_observations = 10 # 10 realizations\n",
    "\n",
    "target_slopes = []\n",
    "reference_slopes = []\n",
    "for n in range(n_observations):\n",
    "    \n",
    "    # Add unique target acq error to the target\n",
    "    current_target = deepcopy(target)\n",
    "    scene.offset_scene(current_target['scene'], *scene.get_ta_error() )\n",
    "    \n",
    "    # Add unique target acq error to the reference\n",
    "    current_reference = deepcopy(reference)\n",
    "    scene.offset_scene(current_reference['scene'], *scene.get_ta_error() )\n",
    "    \n",
    "    # Adopt a new realization of the WFE.\n",
    "    # Note that we're using the same WFE for target and reference here.\n",
    "    engine.options.on_the_fly_webbpsf_opd = ('OPD_RevW_ote_for_NIRCam_predicted.fits', n)\n",
    "    \n",
    "    # Calculate target and reference\n",
    "    targcalc, refcalc = engine.calculate_batch([current_target, current_reference])\n",
    "    target_slopes.append(targcalc['2d']['detector'])\n",
    "    reference_slopes.append(refcalc['2d']['detector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, we make an observation of an off-axis target for the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offaxis = engine.load_calculation( engine.get_template('nircam_coronagraphy_template.json') )\n",
    "offaxis['calculation']['effects']['saturation'] = False # Disable saturation\n",
    "scene.offset_scene(offaxis['scene'], 0.5, 0.5) #arsec\n",
    "\n",
    "offaxis_slope = engine.perform_calculation(offaxis)['2d']['detector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 10 target observations, 10 corresponding reference observations, and 1 off-axis observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "axes[0].imshow(target_slopes[0])\n",
    "axes[0].set_title('1st image in Target Cube')\n",
    "axes[1].imshow(reference_slopes[0])\n",
    "axes[1].set_title('1st image in Reference Cube')\n",
    "axes[2].imshow(offaxis_slope)\n",
    "axes[2].set_title('Off-axis source\\nfor normalization constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Align each reference to its corresponding target and subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subtraction_stack = np.zeros((10,) + target_slopes[0].shape)\n",
    "for i, (targ, ref) in enumerate(zip(target_slopes, reference_slopes)):\n",
    "    aligned_ref = analysis.register_to_target(ref, targ) # Aligned, scaled, mean-centered reference\n",
    "    subtraction_stack[i] = targ - np.nanmean(targ) - aligned_ref # Mean-centered target before subtraction\n",
    "print(subtraction_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (3, 3))\n",
    "ax.imshow(subtraction_stack[0])\n",
    "ax.set_title('1st image in reference-subtracted stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute the covariance matrix from the stack of reference-subtracted targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_matrix = analysis.covariance_matrix(subtraction_stack)\n",
    "print(cov_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute the noise map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll adopt a circular aperture and embed it an array the size of our slope images. (In theory, this aperture could be of any shape or size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import draw\n",
    "image_dim = subtraction_stack[0].shape\n",
    "radius = 5\n",
    "aperture_image = np.zeros(image_dim)\n",
    "aperture_image[draw.circle((image_dim[0] - 1) // 2, (image_dim[1] - 1) // 2, radius)] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "ax.imshow(aperture_image)\n",
    "ax.set_title('Aperture for convolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this aperture, we'll compute an \"aperture matrix\", which is really just the flattened aperture centered at every pixel in the image. It's essentially an intermediate step in a convolution, designed here to match the structure of the covariance matrix we've already computed.\n",
    "\n",
    "And from the covariance and aperture matrices, we can create a map of the correlated noise within that aperture centered at each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aperture_matrix = analysis.aperture_matrix(aperture_image)\n",
    "noise_map = analysis.noise_map(cov_matrix, aperture_matrix, image_dim)\n",
    "print(noise_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "ax.imshow(noise_map)\n",
    "ax.set_title('Correlated noise within our aperture\\nat each pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Take the radial profile of the noise map (normalized by off-axis source in same aperture) to get the contrast curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve the off-axis source with the same aperture and take the maximum. This is the normalization constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "convolved_offaxis = convolve(offaxis_slope, aperture_image, mode='constant')\n",
    "normalization = convolved_offaxis.max()\n",
    "\n",
    "print('Normalization constant (e-/s): ', normalization)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "ax.imshow(convolved_offaxis)\n",
    "ax.set_title('Off-axis source after convolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a radial profile of the noise map, normalize by the constant above, and scale the pixels based on the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins, profile = analysis.radial_profile(noise_map)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "ax.semilogy(bins * 0.031, 5 * profile / normalization)\n",
    "ax.set_xlabel('Separation (arcsec)')\n",
    "ax.set_ylabel('5 sigma Contrast')\n",
    "\n",
    "#mask out any separations < IWA for the NIRCam M210R occulter\n",
    "ax.fill_between([0, 0.4], 1e-7, 1e-3, color = 'k', alpha = 0.3, lw = 0)\n",
    "ax.set_xlim(0,1.9)\n",
    "ax.set_ylim(1e-5,1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Easy Way\n",
    "\n",
    "Once you've settled on an aperture and have generated a set of images, you can pretty much jump through steps 2 - 4 above in a single call to `analysis.compute_contrast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins, normalized_profile = analysis.compute_contrast(subtraction_stack, offaxis_slope, aperture_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "ax.semilogy(bins * 0.031, 5 * normalized_profile)\n",
    "ax.set_xlabel('Separation (arcsec)')\n",
    "ax.set_ylabel('5 sigma Contrast')\n",
    "\n",
    "#mask out any separations < IWA for the NIRCam M210R occulter\n",
    "ax.fill_between([0, 0.4], 1e-7, 1e-3, color = 'k', alpha = 0.3, lw = 0)\n",
    "ax.set_xlim(0,1.9)\n",
    "ax.set_ylim(1e-5,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandeia",
   "language": "python",
   "name": "pandeia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
